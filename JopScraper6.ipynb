{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# develop a simple program to scrape one sigle page on Indeed\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import re\n",
    "\n",
    "web_address = 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start='\n",
    "html = urlopen(web_address)\n",
    "bs = BeautifulSoup(html.read(),'html.parser')\n",
    "Jobs = bs.find_all('div',{'class':'jobsearch-SerpJobCard'}) \n",
    "\n",
    "Joblist=[]\n",
    "for Job in Jobs:\n",
    "    JobTitle = Job.find('a',{'data-tn-element':'jobTitle'})\n",
    "    if JobTitle==None:\n",
    "        JobTitle=Job.find('h2',{'class':'jobtitle'}) \n",
    "    if JobTitle !=None:\n",
    "        Title=JobTitle.get_text().strip('\\n')\n",
    "    else:\n",
    "        Title='TitleMissing'\n",
    "    \n",
    "    Jobcompany = Job.find('span',{'class':'company'})\n",
    "    if Jobcompany !=None:\n",
    "        Company=Jobcompany.get_text().lstrip()\n",
    "    else:\n",
    "        Company='NocompanyName'\n",
    "        \n",
    "    Joblocation = Job.find('span',{'class':'location'})\n",
    "    if Joblocation==None:\n",
    "        Joblocation = Job.find('div',{'class':'location'})\n",
    "    if Joblocation !=None:\n",
    "        Location=Joblocation.get_text()\n",
    "    else:\n",
    "        Location='NoLocation'\n",
    "    \n",
    "    JobSalary = Job.find('span',{'class':'salary no-warp'})\n",
    "    if JobSalary != None:\n",
    "        Salarytext = JobSalary.get_text().lstrip('\\n')\n",
    "        Salary = re.findall(r'\\$[0-9.,-]+',Salarytext)\n",
    "    else:\n",
    "        Salary = 'Notavaliable'\n",
    "        \n",
    "    Jobpostdate = Job.find('span',{'class':'date'})\n",
    "    if Jobpostdate!=None:\n",
    "        Date=Jobpostdate.get_text()\n",
    "    else:\n",
    "        Date='NoDate'\n",
    "           \n",
    "    Jobmatch = Job.find('div',{'class':'serp-ResumeMatch-heading'})\n",
    "    if Jobmatch !=None:\n",
    "        Matcha = Jobmacth.get_text()\n",
    "    else:\n",
    "        Match = 'TBD'\n",
    "    \n",
    "    JobviewerNumbers = Job.find('span',{'class':'slNoUnderline'})\n",
    "    if JobviewerNumbers != None:\n",
    "        Number = JobviewerNumbers.get_text()     \n",
    "    else:\n",
    "        Number = \"NotDisplayed\"\n",
    "    \n",
    "    \n",
    "        \n",
    "        new_Job = [Title,Company,Location,Date,Salary,Match,Number]\n",
    "        \n",
    "        print(new_Job)\n",
    "        Joblist.append(new_Job)\n",
    "# print the list as well\n",
    "print('------------------------------Below is the list and Well Done---------------------------------')\n",
    "print(Joblist)\n",
    "len(Joblist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the results of the first page in a CSV file named 'JobScraper_CSV'.\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import re\n",
    "\n",
    "with open('JobScraper.csv','w',newline='') as myFile:\n",
    "    writer = csv.writer(myFile)\n",
    "    writer.writerow([\"Title\",\"Company\",\"Location\",\"Date\",\"Match\",\"Numberstext\"])\n",
    "\n",
    "\n",
    "web_address = 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start='\n",
    "html = urlopen(web_address)\n",
    "bs = BeautifulSoup(html.read(),'html.parser')\n",
    "Jobs = bs.find_all('div',{'class':'jobsearch-SerpJobCard'}) \n",
    "\n",
    "Joblist=[]\n",
    "for Job in Jobs:\n",
    "    JobTitle = Job.find('a',{'data-tn-element':'jobTitle'})\n",
    "    if JobTitle==None:\n",
    "        JobTitle=Job.find('h2',{'class':'jobtitle'}) \n",
    "    if JobTitle !=None:\n",
    "        Title=JobTitle.get_text().strip('\\n')\n",
    "    else:\n",
    "        Title='TitleMissing'\n",
    "    \n",
    "    Jobcompany = Job.find('span',{'class':'company'})\n",
    "    if Jobcompany !=None:\n",
    "        Company=Jobcompany.get_text().lstrip()\n",
    "    else:\n",
    "        Company='NocompanyName'\n",
    "        \n",
    "    Joblocation = Job.find('span',{'class':'location'})\n",
    "    if Joblocation==None:\n",
    "        Joblocation = Job.find('div',{'class':'location'})\n",
    "    if Joblocation !=None:\n",
    "        Location=Joblocation.get_text()\n",
    "    else:\n",
    "        Location='NoLocation'\n",
    "    \n",
    "    Jobpostdate = Job.find('span',{'class':'date'})\n",
    "    if Jobpostdate!=None:\n",
    "        Date=Jobpostdate.get_text()\n",
    "    else:\n",
    "        Date='NoDate'\n",
    "           \n",
    "    Jobmatch = Job.find('div',{'class':'serp-ResumeMatch-heading'})\n",
    "    if Jobmatch !=None:\n",
    "        Matcha = Jobmacth.get_text()\n",
    "    else:\n",
    "        Match = 'TBD'\n",
    "    \n",
    "    JobviewerNumbers = Job.find('span',{'class':'slNoUnderline'})\n",
    "    if JobviewerNumbers != None:\n",
    "        Number = JobviewerNumbers.get_text()     \n",
    "    else:\n",
    "        Number = \"NotDisplayed\"\n",
    "    \n",
    "    \n",
    "        \n",
    "        new_Job = [Title,Company,Location,Date,Match,Number]\n",
    "        print(new_Job)\n",
    "        Joblist.append(new_Job)\n",
    "        \n",
    "with open('JobScraper.csv','a',newline='',encoding='utf-8') as myFile:\n",
    "    writer = csv.writer(myFile)\n",
    "    writer.writerows(Joblist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat the list of URL's for the most recent 100 jobposting pages\n",
    "\n",
    "baseURL='https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start='\n",
    "\n",
    "urlList=[]\n",
    "for i in range(0,1001,10):\n",
    "    newURL=baseURL + str(i)\n",
    "    urlList.append(newURL)\n",
    "\n",
    "print(urlList[0:50])\n",
    "len(urlList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the scraping into a function so that we can it on different pages. The JobScraper function takes the page number(0,10,20,30,...) as input and returns a list of all the Jobs on the page in a list of lists format\n",
    "\n",
    "def JobScraper(pageNumber):\n",
    "    \n",
    "    baseURL = 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start='\n",
    "    url = baseURL + str(pageNumber)\n",
    "    html = urlopen(web_address)\n",
    "    bs = BeautifulSoup(html.read(),'html.parser')\n",
    "    Jobs = bs.find_all('div',{'class':'jobsearch-SerpJobCard'}) \n",
    "\n",
    "    Joblist=[]\n",
    "    for Job in Jobs:\n",
    "        \n",
    "        JobTitle = Job.find('a',{'data-tn-element':'jobTitle'})\n",
    "        if JobTitle==None:\n",
    "            JobTitle=Job.find('h2',{'class':'jobtitle'}) \n",
    "        if JobTitle !=None:\n",
    "            Title=JobTitle.get_text().strip('\\n')\n",
    "        else:\n",
    "            Title='TitleMissing'\n",
    "    \n",
    "        Jobcompany = Job.find('span',{'class':'company'})\n",
    "        if Jobcompany !=None:\n",
    "            Company=Jobcompany.get_text().lstrip()\n",
    "        else:\n",
    "            Company='NocompanyName'\n",
    "        \n",
    "        Joblocation = Job.find('span',{'class':'location'})\n",
    "        if Joblocation==None:\n",
    "            Joblocation = Job.find('div',{'class':'location'})\n",
    "        if Joblocation !=None:\n",
    "            Location=Joblocation.get_text()\n",
    "        else:\n",
    "            Location='NoLocation'\n",
    "    \n",
    "        Jobpostdate = Job.find('span',{'class':'date'})\n",
    "        if Jobpostdate!=None:\n",
    "            Date=Jobpostdate.get_text()\n",
    "        else:\n",
    "            Date='NoDate'\n",
    "           \n",
    "        Jobmatch = Job.find('div',{'class':'serp-ResumeMatch-heading'})\n",
    "        if Jobmatch !=None:\n",
    "            Match = Jobmacth.get_text()\n",
    "        else:\n",
    "            Match = 'TBD'\n",
    "    \n",
    "        JobviewerNumbers = Job.find('span',{'class':'slNoUnderline'})\n",
    "        if JobviewerNumbers != None:\n",
    "            Numberstext = JobviewerNumbers.get_text()     \n",
    "        else:\n",
    "            Number = \"NotDisplayed\"\n",
    "    \n",
    "    \n",
    "        \n",
    "        new_Job = [Title,Company,Location,Date,Match,Numberstext]\n",
    "        print(new_Job)\n",
    "        Joblist.append(new_Job)\n",
    "        \n",
    "    return Joblist  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JobScraper(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# haddle errors to make the code more robust\n",
    "\n",
    "from urllib.error import HTTPError\n",
    "from urllib.error import URLError\n",
    "\n",
    "def JobScraperwithExceptions(pageNumber):\n",
    "    print('*** Scraping Jobs on page:',int(pageNumber/10 + 1),'***\\n\\n')\n",
    "    \n",
    "    baseURL = 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start='\n",
    "    url = baseURL + str(pageNumber)\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        html = urlopen(url)\n",
    "        \n",
    "    except HTTPError as e1:\n",
    "        print('HTTP request was not responsed')\n",
    "        print('---------------------HTTPError---------------------------')\n",
    "        return None\n",
    "    except URLError as e2:\n",
    "        print('URL can not be opened')\n",
    "        print('---------------------URLError----------------------------')\n",
    "        \n",
    "    bs = BeautifulSoup(html.read(),'html.parser')\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        Jobs = bs.find_all('div',{'class':'jobsearch-SerpJobCard'}) \n",
    "        \n",
    "    except AttributeError as e3:\n",
    "        print('Tag was not found')\n",
    "        print('-------------------AttributeError-----------------------')\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        Joblist = []\n",
    "        \n",
    "        for Job in Jobs:\n",
    "            \n",
    "            JobTitle = Job.find('a',{'data-tn-element':'jobTitle'})\n",
    "            if JobTitle==None:\n",
    "                JobTitle=Job.find('h2',{'class':'jobtitle'}) \n",
    "            if JobTitle !=None:\n",
    "                Title=JobTitle.get_text().strip('\\n')\n",
    "            else:\n",
    "                Title='TitleMissing'\n",
    "            \n",
    "            Jobcompany = Job.find('span',{'class':'company'})\n",
    "            if Jobcompany !=None:\n",
    "                Company=Jobcompany.get_text().lstrip()\n",
    "            else:\n",
    "                Company='NocompanyName'\n",
    "            \n",
    "            Joblocation = Job.find('span',{'class':'location'})\n",
    "            if Joblocation==None:\n",
    "                Joblocation = Job.find('div',{'class':'location'})\n",
    "            if Joblocation !=None:\n",
    "                Location=Joblocation.get_text()\n",
    "            else:\n",
    "                Location='NoLocation'\n",
    "            \n",
    "            Jobpostdate = Job.find('span',{'class':'date'})\n",
    "            if Jobpostdate!=None:\n",
    "                Date=Jobpostdate.get_text()\n",
    "            else:\n",
    "                Date='NoDate'\n",
    "            \n",
    "            Jobmatch = Job.find('div',{'class':'serp-ResumeMatch-heading'})\n",
    "            if Jobmatch !=None:\n",
    "                Match = Jobmacth.get_text()\n",
    "            else:\n",
    "                Match = 'TBD'\n",
    "            \n",
    "            JobviewerNumbers = Job.find('span',{'class':'slNoUnderline'})\n",
    "            if JobviewerNumbers != None:\n",
    "                Numberstext = JobviewerNumbers.get_text()\n",
    "            else:\n",
    "                Number = \"NotDisplayed\"\n",
    "                \n",
    "            \n",
    "                new_Job = [Title,Company,Location,Date,Match]\n",
    "            \n",
    "                Joblist.append(new_Job)\n",
    "            \n",
    "        return Joblist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JobScraperwithExceptions(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the function in a loop and write the results into a csv file\n",
    "\n",
    "with open('JobScraper_Jobs_Final.csv','w',newline='') as myJobsFile:\n",
    "    writer = csv.writer(myJobsFile)\n",
    "    writer.writerow([\"Title\",\"Company\",\"Location\",\"Date\",\"Match\"])\n",
    "    \n",
    "with open('JobScraper_Jobs_Final.csv','a',newline='',encoding='utf-8') as myJobsFile:\n",
    "    writer =csv.writer(myJobsFile)\n",
    "    Joblist=[]\n",
    "    for i in range(0,301,10):\n",
    "        Joblist = JobScraperwithExceptions(i)\n",
    "        writer.writerows(Joblist)\n",
    "        \n",
    "print('-----------------Yes you made it------------------- ')\n",
    "print('-------------Screpting has finished---------------- ')\n",
    "print('---------Data has been writen into file------------ ')\n",
    "print('-----------------You are awesome!------------------ ')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

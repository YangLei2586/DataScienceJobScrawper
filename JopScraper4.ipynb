{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data Scientist', 'NJF Global Holdings', 'New York, NY', 'NoDate', 'Notavaliable', 'TBD', 'NotDisplayed']\n",
      "['Entry Level Analyst, Product Analytics', 'Conde Nast', 'New York, NY 10007 (Financial District area)', '1 day ago', 'Notavaliable', 'TBD', 'NotDisplayed']\n",
      "['Analyst, Entry Level', 'Cloudburst Media', 'New York, NY', '4 hours ago', 'Notavaliable', 'TBD', 'NotDisplayed']\n",
      "['Business Analyst - Database', 'CRSG', 'New York, NY', 'NoDate', 'Notavaliable', 'TBD', 'NotDisplayed']\n",
      "------------------------------Below is the list and Well Done---------------------------------\n",
      "[['Data Scientist', 'NJF Global Holdings', 'New York, NY', 'NoDate', 'Notavaliable', 'TBD', 'NotDisplayed'], ['Entry Level Analyst, Product Analytics', 'Conde Nast', 'New York, NY 10007 (Financial District area)', '1 day ago', 'Notavaliable', 'TBD', 'NotDisplayed'], ['Analyst, Entry Level', 'Cloudburst Media', 'New York, NY', '4 hours ago', 'Notavaliable', 'TBD', 'NotDisplayed'], ['Business Analyst - Database', 'CRSG', 'New York, NY', 'NoDate', 'Notavaliable', 'TBD', 'NotDisplayed']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# develop a simple program to scrape one sigle page on Indeed\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import re\n",
    "\n",
    "web_address = 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start='\n",
    "html = urlopen(web_address)\n",
    "bs = BeautifulSoup(html.read(),'html.parser')\n",
    "Jobs = bs.find_all('div',{'class':'jobsearch-SerpJobCard'}) \n",
    "\n",
    "Joblist=[]\n",
    "for Job in Jobs:\n",
    "    JobTitle = Job.find('a',{'data-tn-element':'jobTitle'})\n",
    "    if JobTitle==None:\n",
    "        JobTitle=Job.find('h2',{'class':'jobtitle'}) \n",
    "    if JobTitle !=None:\n",
    "        Title=JobTitle.get_text().strip('\\n')\n",
    "    else:\n",
    "        Title='TitleMissing'\n",
    "    \n",
    "    Jobcompany = Job.find('span',{'class':'company'})\n",
    "    if Jobcompany !=None:\n",
    "        Company=Jobcompany.get_text().lstrip()\n",
    "    else:\n",
    "        Company='NocompanyName'\n",
    "        \n",
    "    Joblocation = Job.find('span',{'class':'location'})\n",
    "    if Joblocation==None:\n",
    "        Joblocation = Job.find('div',{'class':'location'})\n",
    "    if Joblocation !=None:\n",
    "        Location=Joblocation.get_text()\n",
    "    else:\n",
    "        Location='NoLocation'\n",
    "    \n",
    "    JobSalary = Job.find('span',{'class':'salary no-warp'})\n",
    "    if JobSalary != None:\n",
    "        Salarytext = JobSalary.get_text().lstrip('\\n')\n",
    "        Salary = re.findall(r'\\$[0-9.,-]+',Salarytext)\n",
    "    else:\n",
    "        Salary = 'Notavaliable'\n",
    "        \n",
    "    Jobpostdate = Job.find('span',{'class':'date'})\n",
    "    if Jobpostdate!=None:\n",
    "        Date=Jobpostdate.get_text()\n",
    "    else:\n",
    "        Date='NoDate'\n",
    "           \n",
    "    Jobmatch = Job.find('div',{'class':'serp-ResumeMatch-heading'})\n",
    "    if Jobmatch !=None:\n",
    "        Matcha = Jobmacth.get_text()\n",
    "    else:\n",
    "        Match = 'TBD'\n",
    "    \n",
    "    JobviewerNumbers = Job.find('span',{'class':'slNoUnderline'})\n",
    "    if JobviewerNumbers != None:\n",
    "        Number = JobviewerNumbers.get_text()     \n",
    "    else:\n",
    "        Number = \"NotDisplayed\"\n",
    "    \n",
    "    \n",
    "        \n",
    "        new_Job = [Title,Company,Location,Date,Salary,Match,Number]\n",
    "        \n",
    "        print(new_Job)\n",
    "        Joblist.append(new_Job)\n",
    "# print the list as well\n",
    "print('------------------------------Below is the list and Well Done---------------------------------')\n",
    "print(Joblist)\n",
    "len(Joblist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Business Analyst - Database', 'CRSG', 'New York, NY', '4 days ago', 'TBD', 'NotDisplayed']\n",
      "['Data Scientist', 'NJF Global Holdings', 'New York, NY', 'NoDate', 'TBD', 'NotDisplayed']\n",
      "['Business Intelligence Analyst', 'Access Markets International Partners', 'New York, NY', '3 hours ago', 'TBD', 'NotDisplayed']\n",
      "['Data Analyst (Regulatory Reporting/Trading Operations)', 'Compliance Solutions Strategies', 'New York, NY 10022 (Midtown area)', '15 hours ago', 'TBD', 'NotDisplayed']\n",
      "['Data Governance/Senior Business Analyst', 'Dadata Inc', 'New York, NY', '2 days ago', 'TBD', 'NotDisplayed']\n",
      "['Entry Level Analyst, Product Analytics', 'Conde Nast', 'New York, NY 10007 (Financial District area)', '1 day ago', 'TBD', 'NotDisplayed']\n",
      "['Business Analyst: Hedge Fund and Private Equity', 'IntegriDATA Business & Technology Solutions', 'New York, NY 10168 (Murray Hill area)', '2 hours ago', 'TBD', 'NotDisplayed']\n",
      "['Business Analyst', 'Kultera Inc', 'New York, NY', '4 days ago', 'TBD', 'NotDisplayed']\n",
      "['Analyst, Entry Level', 'Cloudburst Media', 'New York, NY', '4 hours ago', 'TBD', 'NotDisplayed']\n",
      "['Business Analyst - Database', 'CRSG', 'New York, NY', 'NoDate', 'TBD', 'NotDisplayed']\n"
     ]
    }
   ],
   "source": [
    "# write the results of the first page in a CSV file named 'JobScraper_CSV'.\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import re\n",
    "\n",
    "with open('JobScraper.csv','w',newline='') as myFile:\n",
    "    writer = csv.writer(myFile)\n",
    "    writer.writerow([\"Title\",\"Company\",\"Location\",\"Date\",\"Match\",\"Numberstext\"])\n",
    "\n",
    "\n",
    "web_address = 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start='\n",
    "html = urlopen(web_address)\n",
    "bs = BeautifulSoup(html.read(),'html.parser')\n",
    "Jobs = bs.find_all('div',{'class':'jobsearch-SerpJobCard'}) \n",
    "\n",
    "Joblist=[]\n",
    "for Job in Jobs:\n",
    "    JobTitle = Job.find('a',{'data-tn-element':'jobTitle'})\n",
    "    if JobTitle==None:\n",
    "        JobTitle=Job.find('h2',{'class':'jobtitle'}) \n",
    "    if JobTitle !=None:\n",
    "        Title=JobTitle.get_text().strip('\\n')\n",
    "    else:\n",
    "        Title='TitleMissing'\n",
    "    \n",
    "    Jobcompany = Job.find('span',{'class':'company'})\n",
    "    if Jobcompany !=None:\n",
    "        Company=Jobcompany.get_text().lstrip()\n",
    "    else:\n",
    "        Company='NocompanyName'\n",
    "        \n",
    "    Joblocation = Job.find('span',{'class':'location'})\n",
    "    if Joblocation==None:\n",
    "        Joblocation = Job.find('div',{'class':'location'})\n",
    "    if Joblocation !=None:\n",
    "        Location=Joblocation.get_text()\n",
    "    else:\n",
    "        Location='NoLocation'\n",
    "    \n",
    "    Jobpostdate = Job.find('span',{'class':'date'})\n",
    "    if Jobpostdate!=None:\n",
    "        Date=Jobpostdate.get_text()\n",
    "    else:\n",
    "        Date='NoDate'\n",
    "           \n",
    "    Jobmatch = Job.find('div',{'class':'serp-ResumeMatch-heading'})\n",
    "    if Jobmatch !=None:\n",
    "        Matcha = Jobmacth.get_text()\n",
    "    else:\n",
    "        Match = 'TBD'\n",
    "    \n",
    "    JobviewerNumbers = Job.find('span',{'class':'slNoUnderline'})\n",
    "    if JobviewerNumbers != None:\n",
    "        Number = JobviewerNumbers.get_text()     \n",
    "    else:\n",
    "        Number = \"NotDisplayed\"\n",
    "    \n",
    "    \n",
    "        \n",
    "        new_Job = [Title,Company,Location,Date,Match,Number]\n",
    "        print(new_Job)\n",
    "        Joblist.append(new_Job)\n",
    "        \n",
    "with open('JobScraper.csv','a',newline='',encoding='utf-8') as myFile:\n",
    "    writer = csv.writer(myFile)\n",
    "    writer.writerows(Joblist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=0', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=10', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=20', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=30', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=40', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=50', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=60', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=70', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=80', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=90', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=100', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=110', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=120', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=130', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=140', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=150', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=160', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=170', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=180', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=190', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=200', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=210', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=220', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=230', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=240', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=250', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=260', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=270', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=280', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=290', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=300', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=310', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=320', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=330', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=340', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=350', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=360', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=370', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=380', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=390', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=400', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=410', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=420', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=430', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=440', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=450', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=460', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=470', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=480', 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start=490']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creat the list of URL's for the most recent 100 jobposting pages\n",
    "\n",
    "baseURL='https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start='\n",
    "\n",
    "urlList=[]\n",
    "for i in range(0,1001,10):\n",
    "    newURL=baseURL + str(i)\n",
    "    urlList.append(newURL)\n",
    "\n",
    "print(urlList[0:50])\n",
    "len(urlList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the scraping into a function so that we can it on different pages. The JobScraper function takes the page number(0,10,20,30,...) as input and returns a list of all the Jobs on the page in a list of lists format\n",
    "\n",
    "def JobScraper(pageNumber):\n",
    "    \n",
    "    baseURL = 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start='\n",
    "    url = baseURL + str(pageNumber)\n",
    "    html = urlopen(web_address)\n",
    "    bs = BeautifulSoup(html.read(),'html.parser')\n",
    "    Jobs = bs.find_all('div',{'class':'jobsearch-SerpJobCard'}) \n",
    "\n",
    "    Joblist=[]\n",
    "    for Job in Jobs:\n",
    "        \n",
    "        JobTitle = Job.find('a',{'data-tn-element':'jobTitle'})\n",
    "        if JobTitle==None:\n",
    "            JobTitle=Job.find('h2',{'class':'jobtitle'}) \n",
    "        if JobTitle !=None:\n",
    "            Title=JobTitle.get_text().strip('\\n')\n",
    "        else:\n",
    "            Title='TitleMissing'\n",
    "    \n",
    "        Jobcompany = Job.find('span',{'class':'company'})\n",
    "        if Jobcompany !=None:\n",
    "            Company=Jobcompany.get_text().lstrip()\n",
    "        else:\n",
    "            Company='NocompanyName'\n",
    "        \n",
    "        Joblocation = Job.find('span',{'class':'location'})\n",
    "        if Joblocation==None:\n",
    "            Joblocation = Job.find('div',{'class':'location'})\n",
    "        if Joblocation !=None:\n",
    "            Location=Joblocation.get_text()\n",
    "        else:\n",
    "            Location='NoLocation'\n",
    "    \n",
    "        Jobpostdate = Job.find('span',{'class':'date'})\n",
    "        if Jobpostdate!=None:\n",
    "            Date=Jobpostdate.get_text()\n",
    "        else:\n",
    "            Date='NoDate'\n",
    "           \n",
    "        Jobmatch = Job.find('div',{'class':'serp-ResumeMatch-heading'})\n",
    "        if Jobmatch !=None:\n",
    "            Match = Jobmacth.get_text()\n",
    "        else:\n",
    "            Match = 'TBD'\n",
    "    \n",
    "        JobviewerNumbers = Job.find('span',{'class':'slNoUnderline'})\n",
    "        if JobviewerNumbers != None:\n",
    "            Numberstext = JobviewerNumbers.get_text()     \n",
    "        else:\n",
    "            Number = \"NotDisplayed\"\n",
    "    \n",
    "    \n",
    "        \n",
    "        new_Job = [Title,Company,Location,Date,Match,Numberstext]\n",
    "        print(new_Job)\n",
    "        Joblist.append(new_Job)\n",
    "        \n",
    "    return Joblist  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JobScraper(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# haddle errors to make the code more robust\n",
    "\n",
    "from urllib.error import HTTPError\n",
    "from urllib.error import URLError\n",
    "\n",
    "def JobScraperwithExceptions(pageNumber):\n",
    "    print('*** Scraping Jobs on page:',int(pageNumber/10 + 1),'***\\n\\n')\n",
    "    \n",
    "    baseURL = 'https://www.indeed.com/jobs?q=business+analyst%2Cdata+analyst%2Cdata+scientist&l=New+York%2C+NY&start='\n",
    "    url = baseURL + str(pageNumber)\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        html = urlopen(url)\n",
    "        \n",
    "    except HTTPError as e1:\n",
    "        print('HTTP request was not responsed')\n",
    "        print('---------------------HTTPError---------------------------')\n",
    "        return None\n",
    "    except URLError as e2:\n",
    "        print('URL can not be opened')\n",
    "        print('---------------------URLError----------------------------')\n",
    "        \n",
    "    bs = BeautifulSoup(html.read(),'html.parser')\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        Jobs = bs.find_all('div',{'class':'jobsearch-SerpJobCard'}) \n",
    "        \n",
    "    except AttributeError as e3:\n",
    "        print('Tag was not found')\n",
    "        print('-------------------AttributeError-----------------------')\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        Joblist = []\n",
    "        \n",
    "        for Job in Jobs:\n",
    "            \n",
    "            JobTitle = Job.find('a',{'data-tn-element':'jobTitle'})\n",
    "            if JobTitle==None:\n",
    "                JobTitle=Job.find('h2',{'class':'jobtitle'}) \n",
    "            if JobTitle !=None:\n",
    "                Title=JobTitle.get_text().strip('\\n')\n",
    "            else:\n",
    "                Title='TitleMissing'\n",
    "            \n",
    "            Jobcompany = Job.find('span',{'class':'company'})\n",
    "            if Jobcompany !=None:\n",
    "                Company=Jobcompany.get_text().lstrip()\n",
    "            else:\n",
    "                Company='NocompanyName'\n",
    "            \n",
    "            Joblocation = Job.find('span',{'class':'location'})\n",
    "            if Joblocation==None:\n",
    "                Joblocation = Job.find('div',{'class':'location'})\n",
    "            if Joblocation !=None:\n",
    "                Location=Joblocation.get_text()\n",
    "            else:\n",
    "                Location='NoLocation'\n",
    "            \n",
    "            Jobpostdate = Job.find('span',{'class':'date'})\n",
    "            if Jobpostdate!=None:\n",
    "                Date=Jobpostdate.get_text()\n",
    "            else:\n",
    "                Date='NoDate'\n",
    "            \n",
    "            Jobmatch = Job.find('div',{'class':'serp-ResumeMatch-heading'})\n",
    "            if Jobmatch !=None:\n",
    "                Match = Jobmacth.get_text()\n",
    "            else:\n",
    "                Match = 'TBD'\n",
    "            \n",
    "            JobviewerNumbers = Job.find('span',{'class':'slNoUnderline'})\n",
    "            if JobviewerNumbers != None:\n",
    "                Numberstext = JobviewerNumbers.get_text()\n",
    "            else:\n",
    "                Number = \"NotDisplayed\"\n",
    "                \n",
    "            \n",
    "                new_Job = [Title,Company,Location,Date,Match]\n",
    "            \n",
    "                Joblist.append(new_Job)\n",
    "            \n",
    "        return Joblist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Scraping Jobs on page: 4 ***\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Business Analyst', 'Partners Health Plan', 'New York, NY', 'NoDate', 'TBD'],\n",
       " ['Business Analyst',\n",
       "  'IntegriDATA',\n",
       "  'New York, NY 10168 (Murray Hill area)',\n",
       "  '2 days ago',\n",
       "  'TBD'],\n",
       " ['Business Systems Analyst', 'Collibra', 'New York, NY', '1 day ago', 'TBD'],\n",
       " ['Business Analyst',\n",
       "  'SoftVision - North America & UK',\n",
       "  'New York, NY 10018 (Clinton area)',\n",
       "  '9 days ago',\n",
       "  'TBD'],\n",
       " ['Business Analyst',\n",
       "  'Quantum Technologies Inc.',\n",
       "  'New York, NY',\n",
       "  '17 days ago',\n",
       "  'TBD']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JobScraperwithExceptions(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Scraping Jobs on page: 1 ***\n",
      "\n",
      "\n",
      "*** Scraping Jobs on page: 2 ***\n",
      "\n",
      "\n",
      "*** Scraping Jobs on page: 3 ***\n",
      "\n",
      "\n",
      "*** Scraping Jobs on page: 4 ***\n",
      "\n",
      "\n",
      "*** Scraping Jobs on page: 5 ***\n",
      "\n",
      "\n",
      "*** Scraping Jobs on page: 6 ***\n",
      "\n",
      "\n",
      "*** Scraping Jobs on page: 7 ***\n",
      "\n",
      "\n",
      "*** Scraping Jobs on page: 8 ***\n",
      "\n",
      "\n",
      "*** Scraping Jobs on page: 9 ***\n",
      "\n",
      "\n",
      "*** Scraping Jobs on page: 10 ***\n",
      "\n",
      "\n",
      "*** Scraping Jobs on page: 11 ***\n",
      "\n",
      "\n",
      "*** Scraping Jobs on page: 12 ***\n",
      "\n",
      "\n",
      "*** Scraping Jobs on page: 13 ***\n",
      "\n",
      "\n",
      "*** Scraping Jobs on page: 14 ***\n",
      "\n",
      "\n",
      "*** Scraping Jobs on page: 15 ***\n",
      "\n",
      "\n",
      "*** Scraping Jobs on page: 16 ***\n",
      "\n",
      "\n",
      "*** Scraping Jobs on page: 17 ***\n",
      "\n",
      "\n",
      "*** Scraping Jobs on page: 18 ***\n",
      "\n",
      "\n",
      "*** Scraping Jobs on page: 19 ***\n",
      "\n",
      "\n",
      "*** Scraping Jobs on page: 20 ***\n",
      "\n",
      "\n",
      "*** Scraping Jobs on page: 21 ***\n",
      "\n",
      "\n",
      "*** Scraping Jobs on page: 22 ***\n",
      "\n",
      "\n",
      "*** Scraping Jobs on page: 23 ***\n",
      "\n",
      "\n",
      "*** Scraping Jobs on page: 24 ***\n",
      "\n",
      "\n",
      "*** Scraping Jobs on page: 25 ***\n",
      "\n",
      "\n",
      "*** Scraping Jobs on page: 26 ***\n",
      "\n",
      "\n",
      "*** Scraping Jobs on page: 27 ***\n",
      "\n",
      "\n",
      "*** Scraping Jobs on page: 28 ***\n",
      "\n",
      "\n",
      "*** Scraping Jobs on page: 29 ***\n",
      "\n",
      "\n",
      "*** Scraping Jobs on page: 30 ***\n",
      "\n",
      "\n",
      "*** Scraping Jobs on page: 31 ***\n",
      "\n",
      "\n",
      "-----------------Yes you made it------------------- \n",
      "-------------Screpting has finished---------------- \n",
      "---------Data has been writen into file------------ \n",
      "-----------------You are awesome!------------------ \n"
     ]
    }
   ],
   "source": [
    "# run the function in a loop and write the results into a csv file\n",
    "\n",
    "with open('JobScraper_Jobs_Final.csv','w',newline='') as myJobsFile:\n",
    "    writer = csv.writer(myJobsFile)\n",
    "    writer.writerow([\"Title\",\"Company\",\"Location\",\"Date\",\"Match\"])\n",
    "    \n",
    "with open('JobScraper_Jobs_Final.csv','a',newline='',encoding='utf-8') as myJobsFile:\n",
    "    writer =csv.writer(myJobsFile)\n",
    "    Joblist=[]\n",
    "    for i in range(0,301,10):\n",
    "        Joblist = JobScraperwithExceptions(i)\n",
    "        writer.writerows(Joblist)\n",
    "        \n",
    "print('-----------------Yes you made it------------------- ')\n",
    "print('-------------Screpting has finished---------------- ')\n",
    "print('---------Data has been writen into file------------ ')\n",
    "print('-----------------You are awesome!------------------ ')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
